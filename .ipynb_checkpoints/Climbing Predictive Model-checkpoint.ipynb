{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this project is to compare and contrast various popular regression methods - DecisionTreeClassifier, AdaBoost, RandomForestClassifier and XGBoost. I will also be seeing how various processing techniques affect the performance of the models, such as methodologies to deal with NULL values, hyper parameter selection, sandbagging techniques etc. The goal is not to produce the most perfectly fine tuned model (or close to), but to test a range of methodologies used to create regression models and to develop some deeper understanding of their applied nuances. In addition, creating a code repository for different stages of this investigation (visualising decision trees, comparing different models, cross validation, hyper parameter tuning) will be valuable for future projects.\n",
    "\n",
    "The dataset itself is found from Kaggle (https://www.kaggle.com/dcohen21/8anu-climbing-logbook). \n",
    "\n",
    "\n",
    "\n",
    "Previously started this project to predict climber's skill level (arbitrary from https://sportrock.com/understanding-climbing-grades/) and hardest climb achieved.\n",
    "All previous data processing and cleaning was done in python, and  reached memory error when replicating on entire dataset\n",
    "Instead repeated with all manipulation done in SQLite DB brower using the following script:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #sql cleaning script \n",
    "# # creating two tables, one which only selects rows with non null/blank feature variables and the other with the \n",
    "# # complete dataaset with nulls\n",
    "\n",
    "# DROP TABLE IF EXISTS climbing_data_cleaning_1;\n",
    "# CREATE TABLE climbing_data_cleaning_1 AS \n",
    "# SELECT   t1.id as ascent_id\n",
    "# \t\t,t1.user_id\n",
    "# \t\t,t1.rating\n",
    "# \t\t,climb_try\n",
    "# \t\t,UPPER(t3.country) as country\n",
    "# \t\t,CAST(t3.sex as height) as sex\n",
    "# \t\t,CAST(t3.weight as int ) as weight\n",
    "# \t\t,CAST(t3.height as int) as height\n",
    "# \t\t,2020 - t3.started as years_climbing\n",
    "# \t\t,UPPER(t3.occupation) as occupation\n",
    "# \t\t,CASE WHEN sponsor1 > '' OR sponsor2 > '' OR sponsor3 > '' then 1 else 0 end as sponsored\n",
    "# \t\t,count(*) OVER(PARTITION BY user_id) AS number_of_logged_climbs\n",
    "# \t\t,t2.fra_boulders as grade\n",
    "# \t\t,t2.score as grade_number\n",
    "# \t\t,MAX(t2.score) OVER(PARTITION BY user_id) AS max_grade_achieved \n",
    "# \t\t,t4.shorthand\n",
    "# \t\t,CASE WHEN t2.id IS NULL then 1 else 0 end as failed_grade_join \n",
    "# \t\t,CASE WHEN t3.id IS NULL then 1 else 0 end as failed_user_join\n",
    "# \t\t,CASE WHEN t4.id IS NULL then 1 else 0 end as failed_method_join \n",
    "# FROM ascent t1 \n",
    "# LEFT JOIN grade t2 \n",
    "# ON t1.grade_id = t2.id\n",
    "# LEFT JOIN user t3\n",
    "# ON t1.user_id = t3.id\n",
    "# LEFT JOIN method t4\n",
    "# ON t1.method_id = t4.id\n",
    "# WHERE t4.shorthand != 'toprope';\n",
    "\n",
    "# DROP TABLE IF EXISTS climbing_data_cleaning_final_removed_nulls;\n",
    "# CREATE TABLE climbing_data_cleaning_final_removed_nulls AS \n",
    "# SELECT   DISTINCT  user_id\n",
    "# \t\t ,country\n",
    "# \t\t ,sex\n",
    "# \t\t ,weight\n",
    "# \t\t ,height\n",
    "# \t\t ,years_climbing\n",
    "# \t\t ,occupation\n",
    "# \t\t ,sponsored\n",
    "# \t\t ,number_of_logged_climbs\n",
    "# \t\t ,max_grade_achieved AS max_climbing_grade\n",
    "# \t\t ,CASE WHEN max_grade_achieved BETWEEN 0 AND 450 THEN CAST(1 AS int)\n",
    "# \t\t\t   WHEN max_grade_achieved BETWEEN 451 AND 750 THEN  CAST(2 AS int)\n",
    "# \t\t\t   WHEN max_grade_achieved BETWEEN 751 AND 950 THEN CAST(3 AS int)\n",
    "# \t\t\t   WHEN max_grade_achieved > 951 THEN CAST(4 AS int) END AS skill_level\n",
    "# FROM climbing_data_cleaning_1\n",
    "# WHERE occupation > '' \n",
    "# AND height > 0\n",
    "# AND weight > 0;\n",
    "\n",
    "# DROP TABLE IF EXISTS climbing_data_cleaning_final_with_nulls;\n",
    "# CREATE TABLE climbing_data_cleaning_final_with_nulls AS \n",
    "# SELECT   DISTINCT  user_id\n",
    "# \t\t ,country\n",
    "# \t\t ,sex\n",
    "# \t\t ,weight\n",
    "# \t\t ,height\n",
    "# \t\t ,years_climbing\n",
    "# \t\t ,occupation\n",
    "# \t\t ,sponsored\n",
    "# \t\t ,number_of_logged_climbs\n",
    "# \t\t ,max_grade_achieved AS max_climbing_grade\n",
    "# \t\t ,CASE WHEN max_grade_achieved BETWEEN 0 AND 450 THEN CAST(1 AS int)\n",
    "# \t\t\t   WHEN max_grade_achieved BETWEEN 451 AND 750 THEN  CAST(2 AS int)\n",
    "# \t\t\t   WHEN max_grade_achieved BETWEEN 751 AND 950 THEN CAST(3 AS int)\n",
    "# \t\t\t   WHEN max_grade_achieved > 951 THEN CAST(4 AS int) END AS skill_level\n",
    "# FROM climbing_data_cleaning_1;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported all libraries successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Michael\\anaconda3\\lib\\site-packages\\sklearn\\externals\\six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
      "  \"(https://pypi.org/project/six/).\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#Import Libraries \n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "import numpy as np\n",
    "from IPython.display import Image  \n",
    "import matplotlib as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import RandomizedSearchCV \n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.metrics import classification_report \n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.externals.six import StringIO  \n",
    "\n",
    "from graphviz import Source\n",
    "from IPython.display import display\n",
    "from IPython.display import SVG\n",
    "from xgboost import XGBClassifier\n",
    "from tqdm import tqdm\n",
    "\n",
    "print(\"Imported all libraries successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import dataset with no nulls first \n",
    "\n",
    "#using sqlite (unsure how to add relative path connection to sql lite)\n",
    "# con = sqlite3.connect(\"climbing_predictive_model_database.db\")\n",
    "\n",
    "# df_clean = pd.read_sql_query(\"SELECT * from cleaned_data_complete\", con)\n",
    "\n",
    "\n",
    "#using read_csv\n",
    "\n",
    "df_clean = pd.read_csv(\"cleaned_table_removed_nulls.csv\")\n",
    "\n",
    "print(\"Data imported correctly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Project changed to predicting skill level instead of specific max grade. dropping max_climbing_grade and inspecting head\n",
    "df_clean = df_clean.drop('max_climbing_grade', 1)\n",
    "df_clean.head()\n",
    "df_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating dummy variables and adding to dataframe\n",
    "df_dummy_country = pd.get_dummies(df_clean['country'])\n",
    "df_dummy_occupation = pd.get_dummies(df_clean['occupation'])\n",
    "\n",
    "df_clean_final = pd.concat([df_clean,  df_dummy_occupation], axis=1)\n",
    "df_clean_final = df_clean_final.merge(df_dummy_occupation,left_index=True, right_index=True)\n",
    "\n",
    "df_clean_final = pd.concat([df_clean,  df_dummy_country], axis=1)\n",
    "df_clean_final = df_clean_final.merge(df_dummy_country,left_index=True, right_index=True)\n",
    "\n",
    "df_clean_final.head()\n",
    "df_clean_final.info()\n",
    "print(\"Dummy variables created/appended, index reset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualizing the decision tree before any data manipulation \n",
    "clf = DecisionTreeClassifier(max_depth = 4)\n",
    "\n",
    "#dropping categorical variables that we replaced with dummy variables \n",
    "df_clean_X = df_clean_final.loc[:, df_clean_final.columns.drop(['skill_level', 'country', 'occupation'])]\n",
    "#create target variable df \n",
    "df_clean_y = df_clean_final['skill_level']\n",
    "\n",
    "clf.fit(df_clean_X, df_clean_y)\n",
    "\n",
    "graph = Source(tree.export_graphviz(clf\n",
    "                                    ,out_file=None\n",
    "                                    ,filled = True\n",
    "                                    ,feature_names = df_clean_X.columns\n",
    "                                    ,class_names = ['Beginner', 'Intermediate', 'Advanced', 'World Class']))\n",
    "display(SVG(graph.pipe(format='svg')))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting and somewhat expected results. Speaking very generally over the decision tree, climbers with more logged climbs, longer time climbing, low(er) weight tended to climb higher grades. The number of years seperator seemed to be much larger than anticipated, it seems younger climbers do not tend to log their climbs as much as older climbers. Another interesting find is that of climbers with many logged climbs who are not sponsered, those who werre from Sweeden tended to be classified as higher skilled, possibly speaking to their widespread climbing community and high standard of recreational climbers.\n",
    "\n",
    "Speaking more generally over the classifier, having a multi-class regression such as this with 4 target variables leads to relatively high Gini scores. An interesting inestigation would be to repeat this investgiation with a binary classifier (beginner climber/good climber) to see if we can retrieve lower Gini scores. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding the optimal model - data cleaning 1 (optional if we don't want to scale numerical columns)\n",
    "\n",
    "#scaling the columns\n",
    "#set scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "#find numerical columns\n",
    "numeric_columns = df_clean.select_dtypes(include=np.number).columns.tolist()\n",
    "numeric_columns.remove('skill_level')\n",
    "\n",
    "df_clean[numeric_columns] = scaler.fit_transform(df_clean[numeric_columns])\n",
    "print(\"Scaled columns sucessfully\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding the optimal model - data cleaning 2\n",
    "#setting all categorical variables as numerical \n",
    "df_clean['occupation'] = df_clean['occupation'].apply(lambda x: hash(x))\n",
    "df_clean['country'] = df_clean['country'].apply(lambda x: hash(x))\n",
    "\n",
    "print(\"Hash function applied successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating training and test datasets\n",
    "df_decision_tree_X = df_clean.loc[:, df_clean.columns.drop(['skill_level'])]\n",
    "df_decision_tree_y = df_clean['skill_level']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_decision_tree_X, df_decision_tree_y, test_size=0.5, random_state=42)\n",
    "\n",
    "print(\"Training and test datasets split correctly \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this is a mutliclass regression problem, we will be testing these model's accuracy score in lieu of roc_auc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define base models to test '\n",
    "models = [\n",
    "    DecisionTreeClassifier(),\n",
    "    XGBClassifier(\n",
    "                #param={'max_depth':3, 'eta':1, 'objective':'binary:logistic' }\n",
    "                 ),\n",
    "    AdaBoostClassifier(),\n",
    "    LogisticRegression(),\n",
    "    RandomForestClassifier(),\n",
    "]\n",
    "\n",
    "print(\"Models defined correctly\")\n",
    "\n",
    "CV = KFold(n_splits=10)\n",
    "model_scores = []\n",
    "for model in tqmd(models):\n",
    "    model_name = model.__class__.__name__\n",
    "    accuracies = cross_val_score(model, df_decision_tree_X, df_decision_tree_y\n",
    "                                 , scoring='accuracy', cv=CV)\n",
    "    for iteration, accuracy in enumerate(accuracies):\n",
    "        model_scores.append((model_name, iteration, accuracy))\n",
    "\n",
    "print(\"Models ran correctly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating visualisation of all models to compare the accuracy score of each cross validation iteration \n",
    "sns.set(style=\"whitegrid\")\n",
    "model_scores_df = pd.DataFrame(model_scores, columns =['Model', 'Iteration', 'Accuracy Score'])\n",
    "\n",
    "sns.swarmplot(data=model_scores_df, x='Model', y='Accuracy Score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intersting results. AdaBoost, XGBoost and RandomForestClassifier all produce the most accurate models. All of the models exhibit high variance, indicating low bias and possible underfitting. Due to the small amount of features of the dataset, this is somewhat expected and we will try and reduce the variance for more consistent model performance. \n",
    "\n",
    "Recapping our findings so far:\n",
    "\n",
    "We have joined all datasets together in SQL to produce our final table and have removed any rows with null values. We have visualised the variables and found which features/thresholds are the best predictors for climber's skill levels in our dataset. Finally, we have found that our best out-of-the-box model is AdaBoostClassifier/XGBoost/RandomForestClassifier with no hyperparameter tuning.\n",
    "\n",
    "We will now repeat the process using the entire dataset to test different methodologies of dealing with missing/null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data imported correctly\n"
     ]
    }
   ],
   "source": [
    "#import dataset with nulls  \n",
    "\n",
    "#using sqlite (unsure how to add relative path connection to sql lite)\n",
    "# con = sqlite3.connect(r\"climbing_predictive_model_database.sqlite\")\n",
    "\n",
    "# df_clean = pd.read_sql_query(\"SELECT * from cleaned_data_complete\", con)\n",
    "\n",
    "#using read csv\n",
    "df_clean = pd.read_csv(\"cleaned_table_complete.csv\")\n",
    "\n",
    "print(\"Data imported correctly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>country</th>\n",
       "      <th>sex</th>\n",
       "      <th>weight</th>\n",
       "      <th>height</th>\n",
       "      <th>years_climbing</th>\n",
       "      <th>occupation</th>\n",
       "      <th>sponsored</th>\n",
       "      <th>number_of_logged_climbs</th>\n",
       "      <th>skill_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>SWE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>209</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>SWE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>SWE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>SWE</td>\n",
       "      <td>1.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>179</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>USA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>389</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id country  sex  weight  height  years_climbing occupation  sponsored  \\\n",
       "0        1     SWE  0.0    73.0   177.0            24.0        NaN          0   \n",
       "1        2     SWE  0.0     0.0     0.0            20.0        NaN          0   \n",
       "2        3     SWE  0.0    78.0   180.0            25.0        NaN          0   \n",
       "3        4     SWE  1.0    58.0   165.0            19.0        NaN          0   \n",
       "4        5     USA  0.0     0.0     0.0            29.0        NaN          0   \n",
       "\n",
       "   number_of_logged_climbs  skill_level  \n",
       "0                      209            4  \n",
       "1                        7            2  \n",
       "2                       61            4  \n",
       "3                      179            4  \n",
       "4                      389            3  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 35656 entries, 0 to 35655\n",
      "Data columns (total 10 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   user_id                  35656 non-null  int64  \n",
      " 1   country                  35613 non-null  object \n",
      " 2   sex                      35653 non-null  float64\n",
      " 3   weight                   35653 non-null  float64\n",
      " 4   height                   35653 non-null  float64\n",
      " 5   years_climbing           35653 non-null  float64\n",
      " 6   occupation               9245 non-null   object \n",
      " 7   sponsored                35656 non-null  int64  \n",
      " 8   number_of_logged_climbs  35656 non-null  int64  \n",
      " 9   skill_level              35656 non-null  int64  \n",
      "dtypes: float64(4), int64(4), object(2)\n",
      "memory usage: 2.7+ MB\n"
     ]
    }
   ],
   "source": [
    "#Project changed to predicting skill level instead of specific max grade. dropping max_climbing_grade and inspecting head\n",
    "df_clean = df_clean.drop('max_climbing_grade', 1)\n",
    "df_clean.head()\n",
    "df_clean.info()\n",
    "\n",
    "#roughly 5x the amount of data as the dataset with no null values in any of the features\n",
    "#Hopefully this will lead to more accurate models or lower variance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight distribution before replacing values\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0      0.372199\n",
       "68.0     0.133285\n",
       "73.0     0.128629\n",
       "63.0     0.110061\n",
       "78.0     0.070906\n",
       "58.0     0.055087\n",
       "53.0     0.036883\n",
       "83.0     0.036855\n",
       "48.0     0.018764\n",
       "88.0     0.012201\n",
       "43.0     0.006030\n",
       "40.0     0.005806\n",
       "100.0    0.005750\n",
       "93.0     0.005245\n",
       "98.0     0.002300\n",
       "Name: weight, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight distribution after replacing values\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "68.302864     0.372252\n",
       "68.000000     0.133274\n",
       "73.000000     0.128618\n",
       "63.000000     0.110052\n",
       "78.000000     0.070900\n",
       "58.000000     0.055082\n",
       "53.000000     0.036880\n",
       "83.000000     0.036852\n",
       "48.000000     0.018763\n",
       "88.000000     0.012200\n",
       "43.000000     0.006030\n",
       "40.000000     0.005805\n",
       "100.000000    0.005749\n",
       "93.000000     0.005245\n",
       "98.000000     0.002300\n",
       "Name: weight, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#inspecting weight feature\n",
    "print(\"Weight distribution before replacing values\")\n",
    "df_clean['weight'].value_counts(ascending=False, normalize=True)\n",
    "#35% of our weights are 0 value \n",
    "\n",
    "#set 0 values as NAN and replace\n",
    "df_clean['weight'].replace(0, np.nan, inplace= True)\n",
    "mean_weight=df_clean['weight'].mean()\n",
    "df_clean['weight']=df_clean['weight'].fillna(mean_weight)\n",
    "\n",
    "print(\"Weight distribution after replacing values\")\n",
    "df_clean['weight'].value_counts(ascending=False, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Height distribution before replacing values\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0      0.369871\n",
       "180.0    0.054946\n",
       "178.0    0.043615\n",
       "175.0    0.041091\n",
       "170.0    0.037276\n",
       "           ...   \n",
       "254.0    0.000028\n",
       "115.0    0.000028\n",
       "133.0    0.000028\n",
       "20.0     0.000028\n",
       "96.0     0.000028\n",
       "Name: height, Length: 158, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "height distribution after replacing values\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "174.545491    0.369924\n",
       "180.000000    0.054942\n",
       "178.000000    0.043611\n",
       "175.000000    0.041087\n",
       "170.000000    0.037273\n",
       "                ...   \n",
       "115.000000    0.000028\n",
       "254.000000    0.000028\n",
       "3.000000      0.000028\n",
       "89.000000     0.000028\n",
       "25.000000     0.000028\n",
       "Name: height, Length: 158, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#inspecting height feature\n",
    "print(\"Height distribution before replacing values\")\n",
    "df_clean['height'].value_counts(ascending=False, normalize=True)\n",
    "#36% of our weights are 0 value\n",
    "\n",
    "#set 0 values as NAN and replace\n",
    "df_clean['height'].replace(0, np.nan, inplace= True)\n",
    "mean_height=df_clean['height'].mean()\n",
    "df_clean['height']=df_clean['height'].fillna(mean_height)\n",
    "                            \n",
    "print(\"height distribution after replacing values\")\n",
    "df_clean['height'].value_counts(ascending=False, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2020.0    0.298180\n",
       "20.0      0.075898\n",
       "12.0      0.046251\n",
       "13.0      0.045971\n",
       "11.0      0.043475\n",
       "Name: years_climbing, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "16.087243    0.298239\n",
       "20.000000    0.075892\n",
       "12.000000    0.046247\n",
       "13.000000    0.045967\n",
       "11.000000    0.043471\n",
       "Name: years_climbing, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#inspecting years_climbing feature\n",
    "df_clean['years_climbing'].value_counts(ascending=False, normalize=True).head()\n",
    "#30% of values showing as 2020 (previously inserted as 0 in the data)\n",
    "\n",
    "#set 2020 values as NAN and replace\n",
    "df_clean['years_climbing'].replace(2020, np.nan, inplace= True)\n",
    "mean_years_climbing=df_clean['years_climbing'].mean()\n",
    "df_clean['years_climbing']=df_clean['years_climbing'].fillna(mean_years_climbing)\n",
    "\n",
    "df_clean['years_climbing'].value_counts(ascending=False, normalize=True).head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "USA    0.184876\n",
       "ESP    0.111027\n",
       "POL    0.063741\n",
       "DEU    0.060512\n",
       "ITA    0.055261\n",
       "Name: country, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>country</th>\n",
       "      <th>sex</th>\n",
       "      <th>weight</th>\n",
       "      <th>height</th>\n",
       "      <th>years_climbing</th>\n",
       "      <th>occupation</th>\n",
       "      <th>sponsored</th>\n",
       "      <th>number_of_logged_climbs</th>\n",
       "      <th>skill_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [user_id, country, sex, weight, height, years_climbing, occupation, sponsored, number_of_logged_climbs, skill_level]\n",
       "Index: []"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#inspecting country feature\n",
    "n_rows = 5\n",
    "df_clean['country'].value_counts(ascending=False, normalize=True).head(n_rows)\n",
    "\n",
    "#blank values only count for ~1% of our rows. small enough that dropping won't lead to a significant data loss\n",
    "indexNames = df_clean[ df_clean['country'].str.len() <3 ].index\n",
    "df_clean.drop(indexNames, inplace=True)\n",
    "\n",
    "#ensuring that the values were dropped, following should be null \n",
    "df_clean[df_clean['country'].str.len() <3]\n",
    "\n",
    "#after inspecting df_clean.info(), still some NULl values that can be dropped \n",
    "df_clean = df_clean.dropna(subset=['country'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "STUDENT       0.250352\n",
       "ESTUDIANTE    0.019258\n",
       "ENGINEER      0.018825\n",
       "TEACHER       0.014606\n",
       "CLIMBER       0.010927\n",
       "Name: occupation, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "STUDENT       0.805425\n",
       "ESTUDIANTE    0.004998\n",
       "ENGINEER      0.004886\n",
       "TEACHER       0.003791\n",
       "CLIMBER       0.002836\n",
       "Name: occupation, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#inspecting occupation variable\n",
    "df_clean['occupation'].value_counts(ascending=False, normalize=True).head()\n",
    "#70% of values are null. can be good grounds to eliminate this variable completely\n",
    "#especially sice low frequency of other variables . for learning purposes, will test replacing with most common value\n",
    "#and will test replacing the missing values with a ML model at a later stage\n",
    "\n",
    "#replace blanks with NAN\n",
    "df_clean['occupation'].replace('', np.nan, inplace= True)\n",
    "\n",
    "df_clean['occupation'] = df_clean['occupation'].fillna(df_clean['occupation'].value_counts().index[0])\n",
    "\n",
    "df_clean['occupation'].value_counts(ascending=False, normalize=True).head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 35611 entries, 0 to 35655\n",
      "Data columns (total 10 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   user_id                  35611 non-null  int64  \n",
      " 1   country                  35611 non-null  object \n",
      " 2   sex                      35611 non-null  float64\n",
      " 3   weight                   35611 non-null  float64\n",
      " 4   height                   35611 non-null  float64\n",
      " 5   years_climbing           35611 non-null  float64\n",
      " 6   occupation               35611 non-null  object \n",
      " 7   sponsored                35611 non-null  int64  \n",
      " 8   number_of_logged_climbs  35611 non-null  int64  \n",
      " 9   skill_level              35611 non-null  int64  \n",
      "dtypes: float64(4), int64(4), object(2)\n",
      "memory usage: 3.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df_clean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have dealt with missing values in the entire dataset, by dropping rows, replacing with mean values and replacing with most common values, we can apply the same methodology to test our models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                    | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hash function applied successfully\n",
      "feature/target dataframes created sucessfully\n",
      "Models defined correctly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 5/5 [02:03<00:00, 24.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models ran correctly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#define base models to test '\n",
    "df_clean['occupation'] = df_clean['occupation'].apply(lambda x: hash(x))\n",
    "df_clean['country'] = df_clean['country'].apply(lambda x: hash(x))\n",
    "\n",
    "print(\"Hash function applied successfully\")\n",
    "\n",
    "df_model_selection_X = df_clean.loc[:, df_clean.columns.drop(['skill_level', 'occupation'])]\n",
    "df_model_selection_y = df_clean['skill_level']\n",
    "print(\"feature/target dataframes created sucessfully\")\n",
    "\n",
    "models = [\n",
    "    DecisionTreeClassifier(),\n",
    "    XGBClassifier(\n",
    "                #param={'max_depth':3, 'eta':1, 'objective':'binary:logistic' }\n",
    "                 ),\n",
    "    AdaBoostClassifier(),\n",
    "    LogisticRegression(),\n",
    "    RandomForestClassifier()\n",
    "]\n",
    "\n",
    "print(\"Models defined correctly\")\n",
    "\n",
    "CV = k_fold = KFold(n_splits=10) \n",
    "model_scores = []\n",
    "for model in tqdm(models):\n",
    "    model_name = model.__class__.__name__\n",
    "    accuracies = cross_val_score(model, df_model_selection_X, df_model_selection_y\n",
    "                                  , scoring='accuracy', cv=CV)\n",
    "    for iteration, accuracy in enumerate(accuracies):\n",
    "        model_scores.append((model_name, iteration, accuracy))\n",
    "\n",
    "print(\"Models ran correctly\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1fe2ac08448>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#creating visualisation of all models to compare the accuracy score of each cross validation iteration \n",
    "sns.set(style=\"whitegrid\")\n",
    "model_scores_df = pd.DataFrame(model_scores, columns =['Model', 'Iteration', 'Accuracy Score'])\n",
    "\n",
    "sns.swarmplot(data=model_scores_df, x='Model', y='Accuracy Score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The methodology used to deal with the NULLs affected each model simiarly, with most models reducing in accuracy scores but also decreasing in variance. Given the large variance of the first iteration, this is clearly an overall positive outcome. \n",
    "\n",
    "<!-- Interestingly, the methodology used to deal with the nulls affected each model quite differently. DecisionTreeClassifier performed noticeably worse with slightly lower variance, XGBoost performed largely the same, AdaBoostClassifier saw much higher variance in the results performing slightly worse across accuracy scores, with LogisticRegression perfoming noticeably better with respect to accuracy score and lower variance. \n",
    " -->\n",
    "Further study to find our the cause of the lower performance of the models will be performed, but some I assume a large portion of the findings are due to overcorrection of missing values. For a number of variables we replaced 30%+ of them with the mean of the other values. If we had a dataset with more features, likely these features would have been dropped altogether. \n",
    "\n",
    "A common AdaBoost critizism is that it is subject to noisey data and therefore has issues with high variance. While 10 iterations only produced one outlier, it still exemplifies this characteristic. Future projects with more suitable datasets will test to see if we can reduce AdaBoosts variance, or configure XGBoost to increase performance as this is an allegded advantage of XGBoost was that it introduces regularization parameters to reduce overfitting. \n",
    "\n",
    "For now as a final step to this exploratory project, we will select appropriate hyperparameter for RandomForestClassifier (high performance with lowest variance) and calculate precision/recall. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and test datasets split correctly \n"
     ]
    }
   ],
   "source": [
    "#creating training and test datasets\n",
    "df_decision_tree_X = df_clean.loc[:, df_clean.columns.drop(['skill_level'])]\n",
    "df_decision_tree_y = df_clean['skill_level']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_decision_tree_X, df_decision_tree_y, test_size=0.5, random_state=42)\n",
    "\n",
    "print(\"Training and test datasets split correctly \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=None, error_score=nan,\n",
       "                   estimator=RandomForestClassifier(bootstrap=True,\n",
       "                                                    ccp_alpha=0.0,\n",
       "                                                    class_weight=None,\n",
       "                                                    criterion='gini',\n",
       "                                                    max_depth=None,\n",
       "                                                    max_features='auto',\n",
       "                                                    max_leaf_nodes=None,\n",
       "                                                    max_samples=None,\n",
       "                                                    min_impurity_decrease=0.0,\n",
       "                                                    min_impurity_split=None,\n",
       "                                                    min_samples_leaf=1,\n",
       "                                                    min_samples_split=2,\n",
       "                                                    min_weight_fraction_leaf=0.0,\n",
       "                                                    n_estimators=100,\n",
       "                                                    n_jobs=None,\n",
       "                                                    oob_score=False,\n",
       "                                                    random_state=None,\n",
       "                                                    verbose=0,\n",
       "                                                    warm_start=False),\n",
       "                   iid='deprecated', n_iter=10, n_jobs=None,\n",
       "                   param_distributions={'max_depth': [5, 6, 7, 8, 9, 10],\n",
       "                                        'n_estimators': [100, 120, 140, 160,\n",
       "                                                         180, 200]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The highest accuracy score of all RandomForest hyperparameter selections is 51.78320696433586%\n",
      "The following is the best configuration of RandomForestClassifier\n",
      "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
      "                       criterion='gini', max_depth=10, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "#hyperparameter tuning \n",
    "#set parameters to tune\n",
    "\n",
    "n_estimators = [100, 120, 140, 160, 180, 200]\n",
    "max_depth = [5, 6, 7, 8, 9, 10]\n",
    "\n",
    "param_grid = {'n_estimators' : n_estimators,\n",
    "              'max_depth' : max_depth } \n",
    "\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "print(\"Starting grid search \")\n",
    "\n",
    "clf = RandomizedSearchCV(estimator = model,\n",
    "                param_distributions = param_grid,\n",
    "                scoring = 'accuracy',\n",
    "                n_iter = 10,\n",
    "                random_state = 42)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "#prints the best accuracy score \n",
    "print(\"The highest accuracy score of all RandomForest hyperparameter selections is {}%\".format(clf.best_score_*100))\n",
    "\n",
    "#gives the best model/hyper parameter combination \n",
    "print(\"The following is the best configuration of RandomForestClassifier\")\n",
    "print(clf.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=10, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=120,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.58      0.16      0.26      1654\n",
      "           2       0.49      0.67      0.57      5578\n",
      "           3       0.46      0.48      0.47      5707\n",
      "           4       0.65      0.51      0.57      4867\n",
      "\n",
      "    accuracy                           0.52     17806\n",
      "   macro avg       0.55      0.46      0.47     17806\n",
      "weighted avg       0.54      0.52      0.51     17806\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#calculating precision and recall using the best hyperparameter combination as above\n",
    "model = RandomForestClassifier(n_estimators = 120, max_depth = 10)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# precision = precision_score(y_test, y_pred, average = 'weighted')\n",
    "# recall = recall_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "# print(\"The best performing model's precision is %\".format(precision))\n",
    "# print(\"The best performing model's recall is%\".format(recall))\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some key callouts from the classification report:\n",
    "The classificaiton report for a multi-class metric model is more in depth than previously assumed (https://towardsdatascience.com/multi-class-metrics-made-simple-part-i-precision-and-recall-9250280bddc2). Instead of calculating precision/recall for the model as a whole, we must look at it on a per-metric target basis. I am unsure of the efficacy of f1-score in multiclass models, however it is an intersting avenue for further exploration. \n",
    "\n",
    "The world class climbers has the highest precision. Of all the values that the model predicted world class, 65% of them were indeed world class.\n",
    "\n",
    "The intermediate climbers had the highest recall. Of all the intermediate climbers, the model identified 67% of them correctly. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Project learnings:\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alabaster==0.7.12\n",
      "anaconda-client==1.7.2\n",
      "anaconda-navigator==1.9.12\n",
      "anaconda-project==0.8.3\n",
      "argh==0.26.2\n",
      "asn1crypto==1.3.0\n",
      "astroid==2.3.3\n",
      "astropy==4.0\n",
      "atomicwrites==1.3.0\n",
      "attrs==19.3.0\n",
      "autopep8==1.4.4\n",
      "Babel==2.8.0\n",
      "backcall==0.1.0\n",
      "backports.functools-lru-cache==1.6.1\n",
      "backports.shutil-get-terminal-size==1.0.0\n",
      "backports.tempfile==1.0\n",
      "backports.weakref==1.0.post1\n",
      "bcrypt==3.1.7\n",
      "beautifulsoup4==4.8.2\n",
      "bitarray==1.2.1\n",
      "bkcharts==0.2\n",
      "bleach==3.1.0\n",
      "bokeh==1.4.0\n",
      "boto==2.49.0\n",
      "Bottleneck==1.3.2\n",
      "certifi==2019.11.28\n",
      "cffi==1.14.0\n",
      "chardet==3.0.4\n",
      "Click==7.0\n",
      "cloudpickle==1.3.0\n",
      "clyent==1.2.2\n",
      "colorama==0.4.3\n",
      "comtypes==1.1.7\n",
      "conda==4.8.3\n",
      "conda-build==3.18.11\n",
      "conda-package-handling==1.6.0\n",
      "conda-verify==3.4.2\n",
      "contextlib2==0.6.0.post1\n",
      "cryptography==2.8\n",
      "cycler==0.10.0\n",
      "Cython==0.29.15\n",
      "cytoolz==0.10.1\n",
      "dask==2.11.0\n",
      "decorator==4.4.1\n",
      "defusedxml==0.6.0\n",
      "diff-match-patch==20181111\n",
      "distributed==2.11.0\n",
      "docutils==0.16\n",
      "entrypoints==0.3\n",
      "et-xmlfile==1.0.1\n",
      "fastcache==1.1.0\n",
      "filelock==3.0.12\n",
      "flake8==3.7.9\n",
      "Flask==1.1.1\n",
      "fsspec==0.6.2\n",
      "future==0.18.2\n",
      "gevent==1.4.0\n",
      "glob2==0.7\n",
      "graphviz==0.13.2\n",
      "greenlet==0.4.15\n",
      "h5py==2.10.0\n",
      "HeapDict==1.0.1\n",
      "html5lib==1.0.1\n",
      "hypothesis==5.5.4\n",
      "idna==2.8\n",
      "imageio==2.6.1\n",
      "imagesize==1.2.0\n",
      "importlib-metadata==1.5.0\n",
      "intervaltree==3.0.2\n",
      "ipykernel==5.1.4\n",
      "ipython==7.12.0\n",
      "ipython-genutils==0.2.0\n",
      "ipywidgets==7.5.1\n",
      "isort==4.3.21\n",
      "itsdangerous==1.1.0\n",
      "jdcal==1.4.1\n",
      "jedi==0.14.1\n",
      "Jinja2==2.11.1\n",
      "joblib==0.14.1\n",
      "json5==0.9.1\n",
      "jsonschema==3.2.0\n",
      "jupyter==1.0.0\n",
      "jupyter-client==5.3.4\n",
      "jupyter-console==6.1.0\n",
      "jupyter-core==4.6.1\n",
      "jupyterlab==1.2.6\n",
      "jupyterlab-server==1.0.6\n",
      "keyring==21.1.0\n",
      "kiwisolver==1.1.0\n",
      "lazy-object-proxy==1.4.3\n",
      "libarchive-c==2.8\n",
      "llvmlite==0.31.0\n",
      "locket==0.2.0\n",
      "lxml==4.5.0\n",
      "MarkupSafe==1.1.1\n",
      "matplotlib==3.1.3\n",
      "mccabe==0.6.1\n",
      "menuinst==1.4.16\n",
      "mistune==0.8.4\n",
      "mkl-fft==1.0.15\n",
      "mkl-random==1.1.0\n",
      "mkl-service==2.3.0\n",
      "mock==4.0.1\n",
      "more-itertools==8.2.0\n",
      "mpmath==1.1.0\n",
      "msgpack==0.6.1\n",
      "multipledispatch==0.6.0\n",
      "navigator-updater==0.2.1\n",
      "nbconvert==5.6.1\n",
      "nbformat==5.0.4\n",
      "networkx==2.4\n",
      "nltk==3.4.5\n",
      "nose==1.3.7\n",
      "notebook==6.0.3\n",
      "numba==0.48.0\n",
      "numexpr==2.7.1\n",
      "numpy==1.18.1\n",
      "numpydoc==0.9.2\n",
      "olefile==0.46\n",
      "openpyxl==3.0.3\n",
      "packaging==20.1\n",
      "pandas==1.0.1\n",
      "pandocfilters==1.4.2\n",
      "paramiko==2.7.1\n",
      "parso==0.5.2\n",
      "partd==1.1.0\n",
      "path==13.1.0\n",
      "pathlib2==2.3.5\n",
      "pathtools==0.1.2\n",
      "patsy==0.5.1\n",
      "pep8==1.7.1\n",
      "pexpect==4.8.0\n",
      "pickleshare==0.7.5\n",
      "Pillow==7.0.0\n",
      "pkginfo==1.5.0.1\n",
      "pluggy==0.13.1\n",
      "ply==3.11\n",
      "prometheus-client==0.7.1\n",
      "prompt-toolkit==3.0.3\n",
      "psutil==5.6.7\n",
      "py==1.8.1\n",
      "pycodestyle==2.5.0\n",
      "pycosat==0.6.3\n",
      "pycparser==2.19\n",
      "pycrypto==2.6.1\n",
      "pycurl==7.43.0.5\n",
      "pydocstyle==4.0.1\n",
      "pydot==1.4.1\n",
      "pyflakes==2.1.1\n",
      "Pygments==2.5.2\n",
      "pylint==2.4.4\n",
      "PyNaCl==1.3.0\n",
      "pyodbc===4.0.0-unsupported\n",
      "pyOpenSSL==19.1.0\n",
      "pyparsing==2.4.6\n",
      "pyreadline==2.1\n",
      "pyrsistent==0.15.7\n",
      "PySocks==1.7.1\n",
      "pytest==5.3.5\n",
      "pytest-arraydiff==0.3\n",
      "pytest-astropy==0.8.0\n",
      "pytest-astropy-header==0.1.2\n",
      "pytest-doctestplus==0.5.0\n",
      "pytest-openfiles==0.4.0\n",
      "pytest-remotedata==0.3.2\n",
      "python-dateutil==2.8.1\n",
      "python-jsonrpc-server==0.3.4\n",
      "python-language-server==0.31.7\n",
      "pytz==2019.3\n",
      "PyWavelets==1.1.1\n",
      "pywin32==227\n",
      "pywin32-ctypes==0.2.0\n",
      "pywinpty==0.5.7\n",
      "PyYAML==5.3\n",
      "pyzmq==18.1.1\n",
      "QDarkStyle==2.8\n",
      "QtAwesome==0.6.1\n",
      "qtconsole==4.6.0\n",
      "QtPy==1.9.0\n",
      "requests==2.22.0\n",
      "rope==0.16.0\n",
      "Rtree==0.9.3\n",
      "ruamel-yaml==0.15.87\n",
      "scikit-image==0.16.2\n",
      "scikit-learn==0.22.1\n",
      "scipy==1.4.1\n",
      "seaborn==0.10.0\n",
      "Send2Trash==1.5.0\n",
      "simplegeneric==0.8.1\n",
      "singledispatch==3.4.0.3\n",
      "six==1.14.0\n",
      "snowballstemmer==2.0.0\n",
      "sortedcollections==1.1.2\n",
      "sortedcontainers==2.1.0\n",
      "soupsieve==1.9.5\n",
      "Sphinx==2.4.0\n",
      "sphinxcontrib-applehelp==1.0.1\n",
      "sphinxcontrib-devhelp==1.0.1\n",
      "sphinxcontrib-htmlhelp==1.0.2\n",
      "sphinxcontrib-jsmath==1.0.1\n",
      "sphinxcontrib-qthelp==1.0.2\n",
      "sphinxcontrib-serializinghtml==1.1.3\n",
      "sphinxcontrib-websupport==1.2.0\n",
      "spyder==4.0.1\n",
      "spyder-kernels==1.8.1\n",
      "SQLAlchemy==1.3.13\n",
      "statsmodels==0.11.0\n",
      "sympy==1.5.1\n",
      "tables==3.6.1\n",
      "tblib==1.6.0\n",
      "terminado==0.8.3\n",
      "testpath==0.4.4\n",
      "toolz==0.10.0\n",
      "tornado==6.0.3\n",
      "tqdm==4.42.1\n",
      "traitlets==4.3.3\n",
      "ujson==1.35\n",
      "unicodecsv==0.14.1\n",
      "urllib3==1.25.8\n",
      "watchdog==0.10.2\n",
      "wcwidth==0.1.8\n",
      "webencodings==0.5.1\n",
      "Werkzeug==1.0.0\n",
      "widgetsnbextension==3.5.1\n",
      "win-inet-pton==1.1.0\n",
      "win-unicode-console==0.5\n",
      "wincertstore==0.2\n",
      "wrapt==1.11.2\n",
      "xgboost==0.90\n",
      "xlrd==1.2.0\n",
      "XlsxWriter==1.2.7\n",
      "xlwings==0.17.1\n",
      "xlwt==1.3.0\n",
      "xmltodict==0.12.0\n",
      "yapf==0.28.0\n",
      "zict==1.0.0\n",
      "zipp==2.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip freeze"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
